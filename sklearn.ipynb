{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8e9d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:        #enum for sentiments\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        if self.score > 3: \n",
    "            return Sentiment.POSITIVE\n",
    "        elif self.score < 3: \n",
    "            return Sentiment.NEGATIVE\n",
    "        else: \n",
    "            return Sentiment.NEUTRAL\n",
    "        \n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "    \n",
    "    #to avoid bias in training data\n",
    "    def equalize_distribution(self):\n",
    "        #filtering the various sentiments in different lists\n",
    "        negative_reviews = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        neutral_reviews = list(filter(lambda x: x.sentiment == Sentiment.NEUTRAL, self.reviews))\n",
    "        positive_reviews = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        \n",
    "        #common length is the minimum count of sentiment samples that we have in dataset\n",
    "        common_len = min(len(negative_reviews), len(neutral_reviews), len(positive_reviews))\n",
    "\n",
    "        #creating the new list where all the sentiments have equal samples\n",
    "        negative_reviews = negative_reviews[:common_len]\n",
    "        neutral_reviews = neutral_reviews[:common_len]\n",
    "        positive_reviews = positive_reviews[:common_len]\n",
    "\n",
    "        combined = negative_reviews + neutral_reviews + positive_reviews\n",
    "        random.shuffle(combined)\n",
    "        self.reviews = combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f06a998",
   "metadata": {},
   "source": [
    "#### Reading dataset from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f837fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = 'Books_small_10000.json'\n",
    "\n",
    "reviews = []\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b39e3f",
   "metadata": {},
   "source": [
    "#### Preperation of dataset: vectorization of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "531bca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "\n",
    "train_data_cont = ReviewContainer(train_data)\n",
    "test_data_cont = ReviewContainer(test_data)\n",
    "\n",
    "# equalize sentiment samples in the training data & test data\n",
    "train_data_cont.equalize_distribution()\n",
    "test_data_cont.equalize_distribution()\n",
    "\n",
    "#preperation of vectors to feed into models\n",
    "train_data_x = train_data_cont.get_text()\n",
    "train_data_y = train_data_cont.get_sentiment()\n",
    "\n",
    "test_data_x = test_data_cont.get_text()\n",
    "test_data_y = test_data_cont.get_sentiment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d03e8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorized_train_x = vectorizer.fit_transform(train_data_x).toarray()\n",
    "vectorized_test_x = vectorizer.transform(test_data_x).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b6ac8",
   "metadata": {},
   "source": [
    "#### Classification models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4696a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4342948717948718"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GAUSSIAN NAIVE BAYES\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(vectorized_train_x, train_data_y)\n",
    "\n",
    "clf_gnb.score(vectorized_test_x, test_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9917ad12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5993589743589743"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SUPPORT VECTOR CLASSIFICATION\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svc = SVC()\n",
    "clf_svc.fit(vectorized_train_x, train_data_y)\n",
    "\n",
    "clf_svc.score(vectorized_test_x, test_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec804b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44711538461538464"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dtc = DecisionTreeClassifier()\n",
    "clf_dtc.fit(vectorized_train_x, train_data_y)\n",
    "\n",
    "clf_dtc.score(vectorized_test_x, test_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ed873",
   "metadata": {},
   "source": [
    "#### Evaluation of models: f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a8f705a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB:  [0.46786632 0.40089087 0.43902439]\n",
      "SVC:  [0.6888361  0.51551313 0.59313725]\n",
      "Decision Tree Classifier:  [0.49308756 0.39902676 0.44665012]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"GaussianNB: \", f1_score(test_data_y, clf_gnb.predict(vectorized_test_x), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(\"SVC: \", f1_score(test_data_y, clf_svc.predict(vectorized_test_x), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(\"Decision Tree Classifier: \", f1_score(test_data_y, clf_dtc.predict(vectorized_test_x), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91163ee",
   "metadata": {},
   "source": [
    "#### SVC seems to be the best model here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0bd285",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd96183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.5993589743589743\n",
      "F1 score:  [0.6888361  0.51551313 0.59313725]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, {'kernel': ['linear', 'rbf'], 'C': [1, 2, 4, 8, 16]}, cv= 5)\n",
    "clf.fit(vectorized_train_x, train_data_y)\n",
    "\n",
    "print(\"Mean score: \", clf.score(vectorized_test_x, test_data_y))\n",
    "print(\"F1 score: \", f1_score(test_data_y, clf.predict(vectorized_test_x), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19df56",
   "metadata": {},
   "source": [
    "#### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0284ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('clf_save.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7dcebf",
   "metadata": {},
   "source": [
    "#### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e114c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.5993589743589743\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('clf_save.pkl', 'rb') as f:\n",
    "    saved_clf = pickle.load(f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
